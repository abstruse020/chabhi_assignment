{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from sentence_transformers import SentenceTransformer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VECTOR_SPACE_PATH = \"/kaggle/input/chaabi/space.pkl\"\n",
    "BERT_MODEL_PATH = \"bert-question-answering.pkl\"\n",
    "ENC_PATH  = \"encodermodel.pkl\"\n",
    "QDRANT_PATH  = \"qdrant_vectorsdb_client.pkl\"\n",
    "\n",
    "\n",
    "# with open(VECTOR_SPACE_PATH, 'rb') as file:\n",
    "#     vs = pickle.load(file)\n",
    "# bert llm\n",
    "with open(BERT_MODEL_PATH, 'rb') as file:\n",
    "    bert = pickle.load(file)\n",
    "\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(QDRANT_PATH, 'rb') as file:\n",
    "    qdrant_client = pickle.load(file)\n",
    "\n",
    "with open(ENC_PATH, 'rb') as file:\n",
    "    st_encoder = pickle.load(file)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection_name = \"qdrant-space\"\n",
    "def find_close_contexts(question: str, top_k: int) -> list[str]:\n",
    "    \"\"\"\n",
    "    will return contexts contexts close to query \n",
    "\n",
    "    Args:\n",
    "        question (str): What do we want to know?\n",
    "        top_k (int): top k results will be added \n",
    "\n",
    "    Returns:\n",
    "        context (List[str]):\n",
    "    \"\"\"\n",
    "    try:\n",
    "        encoded_query = st_encoder.encode(question).tolist() \n",
    "        result = qdrant_client.search(\n",
    "            collection_name=collection_name,\n",
    "            query_vector=encoded_query,\n",
    "            limit=top_k,\n",
    "        )  # search qdrant collection for context passage with the answer\n",
    "\n",
    "        context = [\n",
    "            [context.payload[\"product\"], context.payload[\"story\"]] for context in result\n",
    "        ] \n",
    "        return context\n",
    "    except Exception as e:\n",
    "        print({e})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tell_me(question: str, context: list[str]):\n",
    "    \"\"\"\n",
    "    Extract the answer from the context for a given question\n",
    "\n",
    "    Args:\n",
    "        question (str): _description_\n",
    "        context (list[str]): _description_\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    for c in context:\n",
    "        answer = bert(question=question, context=c[1] )\n",
    "        answer[\"product\"] = c[0]\n",
    "        results.append(answer)\n",
    "        print()\n",
    "\n",
    "    sorted_result = sorted(results, key=lambda x: x[\"score\"], reverse=True)\n",
    "    for i in range(len(sorted_result)):\n",
    "        _out = sorted_result[i][\"answer\"] \n",
    "        _prod = sorted_result[i][\"product\"]\n",
    "        _sco = sorted_result[i][\"score\"]\n",
    "#         print(f\"{i+1}\", end=\" \")\n",
    "        print(f\"QUERY INPUT: {question}\")\n",
    "        print(f\"OUTPUT: {_out} \\nPREDICTION SCORE {_sco}\\n\\nReferred Product: {_prod}\\n\\n\")\n",
    "        return question,_out,_sco,_prod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = []\n",
    "queries.append(\"suggest me one product for cleaning vegetables\")\n",
    "queries.append(\"what is the rating of product Vegetable & Fruit Wash with 100% Natural Action\")\n",
    "queries.append(\"what is most loved beauty product\")\n",
    "queries.append(\"price of dove soap\")\n",
    "queries.append(\"what is most loved beauty product\")\n",
    "queries.append(\"suggest one Tea Product\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"result.txt\",\"w\") as result:\n",
    "    for q in queries:\n",
    "        \n",
    "        c = find_close_contexts(q, top_k=1)\n",
    "        _ques,_out,_sco,_prod = tell_me(q,c)\n",
    "        result.write(f\"QUERY INPUT: {_ques}\\nOUTPUT: {_out} \\nPREDICTION SCORE {_sco}\\n\\nReferred Product: {_prod}\\n\\n\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
